{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_path = os.path.expanduser('~/workspace/MobileFaceNet_TF_i/datasets/faces_webface_112x112/train.idx')\n",
    "rec_path = os.path.expanduser('~/workspace/MobileFaceNet_TF_i/datasets/faces_webface_112x112/train.rec')\n",
    "imgrec = mx.recordio.MXIndexedRecordIO(idx_path, rec_path, 'r')\n",
    "\n",
    "s = imgrec.read_idx(0)\n",
    "header,_ = mx.recordio.unpack(s)\n",
    "# HEADER(flag=2, label=array([490624., 501196.], dtype=float32), id=0, id2=0)\n",
    "imgidx = list(range(1, int(header.label[0])))\n",
    "\n",
    "# 图片数量\n",
    "pic_number = int(header.label[0]) - 1\n",
    "# 类别数量\n",
    "class_number = int(header.label[1]) - int(header.label[0])\n",
    "\n",
    "pics = []\n",
    "\n",
    "for i, index in enumerate(imgidx):\n",
    "    img_info = imgrec.read_idx(index)\n",
    "    header, img_raw = mx.recordio.unpack(img_info)\n",
    "    label = int(header.label)\n",
    "    \n",
    "    pics.append([label, img_raw])\n",
    "\n",
    "print(len(pics)) # 490623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(example_proto):\n",
    "    features = {'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "                'label': tf.FixedLenFeature([], tf.int64)}\n",
    "    features = tf.parse_single_example(example_proto, features)\n",
    "    # You can do more image distortion here for training data\n",
    "    img = tf.image.decode_image(features['image_raw'])\n",
    "    img = tf.reshape(img, shape=(112, 112, 3))\n",
    "\n",
    "    #img = tf.py_func(random_rotate_image, [img], tf.uint8)\n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    img = tf.subtract(img, 127.5)\n",
    "    img = tf.multiply(img,  0.0078125)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    label = tf.cast(features['label'], tf.int64)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "tfrecord_path = 'C:/Users/mengf/workspace/MobileFaceNet_TF_i/datasets/faces_webface_112x112/tfrecords/tran.tfrecords'\n",
    "# test tfrecord\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "sess = tf.Session(config=config)\n",
    "# training datasets api config\n",
    "tfrecords_f = os.path.join(tfrecord_path)\n",
    "dataset = tf.data.TFRecordDataset(tfrecords_f)\n",
    "dataset = dataset.map(parse_function)\n",
    "dataset = dataset.shuffle(buffer_size=20000)\n",
    "dataset = dataset.batch(32)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "# begin iteration\n",
    "for i in range(1000):\n",
    "    sess.run(iterator.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            images, labels = sess.run(next_element)\n",
    "            for i in range(len(img)):\n",
    "                images[i,...] = cv2.cvtColor(images[i, ...], cv2.COLOR_RGB2BGR)\n",
    "            cv2.imshow('test', img)\n",
    "            cv2.waitKey(0)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator(tfrecord_path='C:/Users/mengf/workspace/MobileFaceNet_TF_i/datasets/faces_webface_112x112/tfrecords/tran.tfrecords',batch_size=32,out_num=10572):\n",
    "    \"\"\"自定义generator\n",
    "    \n",
    "    # Argument\n",
    "        tfrecord_path:\n",
    "        batch_size\n",
    "        out_num: 类别数量，用于生成onehot\n",
    "        \n",
    "    # Return\n",
    "    \n",
    "    \"\"\"\n",
    "    def parse_function(example_proto):\n",
    "        features = {'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "                    'label': tf.FixedLenFeature([], tf.int64)}\n",
    "        features = tf.parse_single_example(example_proto, features)\n",
    "        # You can do more image distortion here for training data\n",
    "        img = tf.image.decode_jpeg(features['image_raw'])\n",
    "        img = tf.reshape(img, shape=(112, 112, 3))\n",
    "\n",
    "        #img = tf.py_func(random_rotate_image, [img], tf.uint8)\n",
    "        img = tf.cast(img, dtype=tf.float32)\n",
    "        img = tf.subtract(img, 127.5)\n",
    "        img = tf.multiply(img,  0.0078125)\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        label = tf.cast(features['label'], tf.int64)\n",
    "        label = tf.one_hot(label,out_num)\n",
    "        return img, label\n",
    "    \n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    sess = tf.Session(config=config)\n",
    "    # training datasets api config\n",
    "    tfrecords_f = os.path.join(tfrecord_path)\n",
    "    dataset = tf.data.TFRecordDataset(tfrecords_f)\n",
    "    dataset = dataset.map(parse_function)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "    # begin iteration\n",
    "    while(True):\n",
    "        sess.run(iterator.initializer)\n",
    "        while True:\n",
    "            try:\n",
    "                images, labels = sess.run(next_element)\n",
    "                for i in range(len(images)):\n",
    "                    images[i,...] = cv2.cvtColor(images[i, ...], cv2.COLOR_RGB2BGR)\n",
    "                yield images,labels\n",
    "            except tf.errors.OutOfRangeError:\n",
    "#                 print(\"End of dataset\")\n",
    "                pass\n",
    "\n",
    "def my_generator_wrapper():\n",
    "    for image,label in my_generator():\n",
    "        yield ([image,label],label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
